# PropertyAI - Flask Web Application

A modern, enterprise-grade Flask web application for Chilean real estate property valuation using ONNX-optimized machine learning models with interactive map interface.

## ğŸš€ Quick Start

### Local Development
```bash
cd flask-app
./run-local.sh
```

### Docker Deployment (Recommended)
```bash
cd flask-app
./run-docker.sh
```

Visit `http://localhost:5002` to use the web interface.

## ğŸ“ Self-Contained Architecture

### Directory Structure
```
flask-app/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ predictor.py         # Main predictor class
â”‚   â””â”€â”€ bestmodel/           # Embedded best model (auto-generated)
â”‚       â”œâ”€â”€ model.onnx       # ONNX model for fast inference
â”‚       â”œâ”€â”€ preprocessor.pkl # Data preprocessing pipeline
â”‚       â””â”€â”€ metadata.json    # Model information & metrics
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ base.html            # Modern enterprise layout
â”‚   â”œâ”€â”€ index.html           # Interactive form with map
â”‚   â”œâ”€â”€ result.html          # Prediction results
â”‚   â””â”€â”€ model_info.html      # Model information page
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â”œâ”€â”€ style.css        # Modern enterprise styling
â”‚   â”‚   â””â”€â”€ results.css      # Results modal styling
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ app.js           # Interactive map & form logic
â”‚       â””â”€â”€ debug.js         # Debug utilities
â”œâ”€â”€ prepare-model.py         # Best model preparation script
â”œâ”€â”€ run-local.sh            # Local development script
â”œâ”€â”€ run-docker.sh           # Docker deployment script
â”œâ”€â”€ Dockerfile              # Container configuration
â”œâ”€â”€ docker-compose.yml      # Service orchestration
â”œâ”€â”€ gunicorn.conf.py        # Production server config
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ app.py                  # Flask application
```

## ğŸ”„ Simplified Data Flow

```
1. prepare-model.py â†’ Selects best model from pipeline
2. Creates bestmodel/ â†’ 3 files (ONNX, preprocessor, metadata)
3. Flask app loads â†’ From local bestmodel/ directory
4. User request â†’ Preprocessor + ONNX inference â†’ Response
```

## ğŸŒŸ Key Features

### ğŸ¨ Modern Enterprise UI
- **Interactive Map**: Leaflet-based map for location selection
- **Responsive Design**: Works on desktop, tablet, and mobile
- **Draggable Modal**: Resizable and draggable results display
- **Professional Styling**: Clean, modern enterprise design
- **Real-time Validation**: Instant feedback on form inputs

### ğŸ“Š Smart Property Valuation
- **6 Santiago Sectors**: Las Condes, Vitacura, Lo Barnechea, Ã‘uÃ±oa, Providencia, La Reina
- **15,352+ Training Properties**: Comprehensive dataset coverage
- **Automatic Best Model**: Selects optimal model based on configured metric
- **Price per mÂ² Calculation**: Automatic area-based pricing

### ğŸš€ Self-Contained Architecture
- **No External Dependencies**: Everything embedded in bestmodel/ folder
- **ONNX Optimization**: 10-50x faster inference than sklearn
- **Automatic Model Selection**: Uses metric from `src/config.py`
- **Zero Configuration**: Hardcoded defaults for simplicity

### ğŸ” Intelligent Model Management
- **Dynamic Selection**: Automatically finds best performing model
- **Metadata-Driven**: All info comes from model metadata
- **Version Agnostic**: Works with any model version (v2.1, v2.2, v2.3, etc.)

## ğŸ—ï¸ Model Preparation Process

### Automatic Best Model Selection
```bash
# Run prepare-model.py (automatically called by run scripts)
ğŸ” Scanning for available models...
ğŸ“Š Found 3 models
ğŸ† Selected best model: v2.3_gradient_boosting_property_valuation.pkl (metric: mae)
ğŸ“¦ Loading model...
ğŸ’¾ Saving model components...
ğŸ”„ Converting to ONNX...
âœ… Best model prepared successfully
```

### What Gets Created
```
models/bestmodel/
â”œâ”€â”€ model.onnx          # Fast ONNX inference model
â”œâ”€â”€ preprocessor.pkl    # Sklearn preprocessing pipeline  
â””â”€â”€ metadata.json       # Complete model information
```

## ğŸ³ Docker Deployment

### Self-Contained Container
```bash
./run-docker.sh
â”œâ”€â”€ Prepares best model locally
â”œâ”€â”€ Embeds model in Docker image
â”œâ”€â”€ Builds self-contained container
â””â”€â”€ Runs with zero external dependencies
```

### Production Features
- **Embedded Models**: No volume mounts needed
- **Gunicorn WSGI**: Production server with 2 workers
- **Health Checks**: Automatic container monitoring
- **Auto Restart**: Container restarts on failure
- **Instant Startup**: Pre-converted ONNX models

### Container Structure
```
Container /app/
â”œâ”€â”€ src/config.py              # Configuration from main project
â”œâ”€â”€ models/bestmodel/          # Embedded best model
â”‚   â”œâ”€â”€ model.onnx            # Fast inference
â”‚   â”œâ”€â”€ preprocessor.pkl      # Data processing
â”‚   â””â”€â”€ metadata.json         # Model info
â”œâ”€â”€ app.py                    # Flask application
â””â”€â”€ All dependencies included
```

## ğŸŒ API Endpoints

- **`GET /`** - Main web interface with interactive map
- **`POST /predict`** - Property valuation API (JSON)
- **`GET /health`** - Health check endpoint
- **`GET /model/info`** - Model information page
- **`GET /api/model/info`** - Model metadata API

## ğŸ“Š Model Information Display

The `/model/info` page shows:
- **Model Type**: gradient_boosting
- **Inference Engine**: ONNX Runtime (fast predictions)
- **Preprocessing Engine**: Scikit-learn Pipeline (data processing)
- **Selection Metric**: MAE/RMSE (from config)
- **Best Score**: Actual performance metric
- **Original Model Path**: Source location
- **Performance Metrics**: RMSE, MAE, MAPE
- **Features**: All input features
- **Timestamp**: Model training time

## ğŸ“ˆ Performance

- **ONNX Inference**: ~10-50x faster than sklearn
- **Sub-second Response**: < 100ms prediction time
- **Memory Efficient**: Optimized model format
- **Concurrent Users**: Supports multiple simultaneous requests
- **Instant Startup**: Pre-converted models

## ğŸ¯ Usage Examples

### Local Development
```bash
cd flask-app
./run-local.sh
# Automatically prepares best model and starts Flask
```

### Docker Production
```bash
cd flask-app
./run-docker.sh
# Prepares model, builds container, and deploys
```

### API Usage
```bash
curl -X POST http://localhost:5002/predict \
  -H "Content-Type: application/json" \
  -d '{
    "features": {
      "type": "departamento",
      "sector": "las condes",
      "net_usable_area": 120.5,
      "net_area": 150.0,
      "n_rooms": 3,
      "n_bathroom": 2,
      "latitude": -33.4172,
      "longitude": -70.5476
    }
  }'
```

### Health Check
```bash
curl http://localhost:5002/health
# Returns: {"status": "healthy", "model_loaded": true, ...}
```

## ğŸ”§ Configuration

### Model Selection
The best model is automatically selected based on the metric defined in `src/config.py`:
```python
MODEL_METRIC = os.getenv("MODEL_METRIC", "mae")  # mae, rmse, or mape
```

### Hardcoded Settings (Zero Config)
- **Host**: 0.0.0.0
- **Port**: 5000 (mapped to 5002 in Docker)
- **Workers**: 2 (Gunicorn)
- **Debug**: False (Production)

## ğŸ¯ Key Benefits

1. **Zero Configuration**: Works out of the box
2. **Self-Contained**: No external dependencies
3. **Automatic**: Best model selection and preparation
4. **Fast**: ONNX-optimized inference
5. **Portable**: Docker image works anywhere
6. **Production Ready**: Gunicorn, health checks, monitoring

## ğŸ”— Related Documentation

- **[Main Project README](../README.md)** - Complete ML pipeline documentation
- **[API Documentation](../docs/api-documentation.md)** - Full API reference