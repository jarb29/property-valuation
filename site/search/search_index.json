{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Property Valuation ML System","text":"<p>Machine learning system for Chilean real estate property valuation.</p>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":"<p>Get up and running in minutes:</p> DockerLocal <pre><code>git clone https://github.com/jarb29/property-valuation\ncd property-valuation\n\n# Create data directory and add your data\nmkdir -p data/v1\n# Copy your train.csv and test.csv to data/v1/\n\n# Run the ML pipeline first\ndocker-compose --profile pipeline up pipeline\n\n# Then start the API\ndocker-compose up api\n</code></pre> <pre><code>git clone https://github.com/jarb29/property-valuation\ncd property-valuation\n\n# Create data directory and add your data\nmkdir -p data/v1\n# Copy your train.csv and test.csv to data/v1/\n\n# Set up environment\npython -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n\n# Run the ML pipeline first\nDATA_VERSION=v1 python scripts/pipeline.py\n\n# Then start the API\npython scripts/run_api.py\n</code></pre>"},{"location":"#model-configuration","title":"\ud83d\udd27 Model Configuration","text":"<p>The system automatically selects the best model based on your criteria (configured in <code>src/config.py</code>):</p> <pre><code># Configure model selection\nMODEL_METRIC=rmse        # Choose best model by RMSE\nMODEL_LOAD_TARGET=pipeline  # Load from pipeline outputs\nDATA_VERSION=v1          # Use v1 dataset\n</code></pre> <p>Important: Data Version Selection</p> <p>You MUST specify which data version to use: <pre><code>DATA_VERSION=v1  # \u26a0\ufe0f REQUIRED: Select your data version\n</code></pre> Available versions: <code>v1</code>, <code>v2</code>, <code>v3</code>...</p> <p>Available Metrics: <code>rmse</code>, <code>mae</code>, <code>mape</code> Model Sources: <code>pipeline</code>, <code>jupyter</code></p>"},{"location":"#performance","title":"\ud83d\udcca Performance","text":"Metric Current Target Selection RMSE 5,749 CLP &lt; 6,000 <code>MODEL_METRIC=rmse</code> MAE 2,622 CLP &lt; 3,000 <code>MODEL_METRIC=mae</code> MAPE 46.5% &lt; 50% <code>MODEL_METRIC=mape</code> Response Time 23ms &lt; 50ms -"},{"location":"#test-it-now","title":"\ud83c\udfaf Test It Now","text":"<pre><code>curl -X POST http://localhost:8000/api/v1/predictions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-API-Key: default_api_key\" \\\n  -d '{\"features\": {\"type\": \"departamento\", \"sector\": \"las condes\", \"net_usable_area\": 120.5, \"net_area\": 150.0, \"n_rooms\": 3, \"n_bathroom\": 2, \"latitude\": -33.4172, \"longitude\": -70.5476}}'\n</code></pre>"},{"location":"#features","title":"\u2728 Features","text":"<ul> <li>\ud83e\udd16 ML Pipeline - Automated training and evaluation</li> <li>\ud83d\ude80 REST API - Production-ready endpoints</li> <li>\ud83d\udcca Data Versioning - Complete traceability</li> <li>\ud83d\udc33 Docker Ready - Containerized deployment</li> <li>\ud83c\udfaf Smart Model Selection - Automatic best model selection by metric</li> <li>\ud83d\udcc8 Monitoring - Comprehensive logging</li> </ul>"},{"location":"#documentation","title":"\ud83d\udcda Documentation","text":"<ul> <li>Getting Started - Setup and installation</li> <li>User Manual - Complete system guide  </li> <li>API Reference - Endpoint documentation</li> <li>Challenge - Original requirements</li> </ul>"},{"location":"Challenge/","title":"Property-Friends Real State case","text":"<p>This is an hypothetical scenario and is not related with an actual project.</p>"},{"location":"Challenge/#context","title":"Context","text":"<p>Your team has been assigned the task of developing a model to estimate property valuations for an important real estate client in Chile. The idea of the client is deliver quickly a model (even if not the best one) into production so the team can develop the required infraestructure for supporting future new models/projects.</p> <p>The client requires a streamlined process for conducting property appraisals, and they seek to leverage machine learning techniques to achieve quick and reliable estimates. Your team was responsible for building a model that can predict the cost of residential properties in Chile based on property features.</p> <p>After some experimentations the Client is happy with the current results and wants to bring the model into a deployable solution.</p>"},{"location":"Challenge/#task-required","title":"Task Required","text":"<p>Your task is to productivize the existing Jupyter Notebook, ensuring that coding best practices are followed throughout the process. You will be responsible for creating a robust pipeline that automates the model training, evaluation, and deployment process. Additionally, you need to develop an API that can receive property information and provide accurate valuation predictions.</p> <p>It is crucial to document any assumptions made during the development of the model and highlight potential areas of improvement. To facilitate this, you are required to provide a comprehensive README file explaining the project's structure, dependencies, and instructions for running the pipeline and API.</p>"},{"location":"Challenge/#material-provided","title":"Material Provided:","text":"<ol> <li>Property-Friends-basic-model.ipynb: Notebook with the actual code that trains the model.</li> <li>train.csv, test.csv: Datasets used for training and evaluating the model.</li> </ol>"},{"location":"Challenge/#deliverables","title":"Deliverables:","text":"<ol> <li>A well-structured pipeline that trains the property valuation model using the provided dataset, ensuring reproducibility and scalability.</li> <li>An API that can receive property information and generate accurate valuation predictions.</li> <li>A README file documenting the project, including instructions for running the pipeline and API, dependencies, and any assumptions or suggestions for improvement.</li> </ol> <p>Right now the model uses two files: <code>train.csv</code>, <code>test.csv</code> for training. In the future the client wants to connects the pipeline directly into their databases, they asked for us to create the abstractions for acomplish this on the future.</p> <p>Some technicals requirements required from the Software Engineers and MLEngineers: 1. The pipeline and API should run using Docker. 2. API calls/predictions should generate logs using a logger for future model monitoring. 3. API should be documented, its recomendable to use a framework as FastAPI or similar. 4. The client asked for basic security system for the API (API-Keys or similar).</p> <p>The deliverable should be a Github repository containing all the requested. The repository shouldn't contain the data due is property of the client.</p> <p>Note: As you develop the pipeline and API, adhere to coding best practices, including modularization, documentation, and error handling. Consider potential edge cases and handle them appropriately to ensure reliable performance. The client values clean, maintainable code that can be easily scaled and extended in the future.</p>"},{"location":"api-documentation/","title":"API Reference","text":"<p>Complete reference for the Property Valuation ML System REST API. This API provides enterprise-grade property valuation services with comprehensive validation, authentication, and monitoring.</p>"},{"location":"api-documentation/#authentication","title":"\ud83d\udd10 Authentication","text":"<p>The API uses API key authentication for secure access:</p> <pre><code>X-API-Key: your_api_key_here\n</code></pre> <p>API Key Configuration</p> <p>The API key is configured via the <code>API_KEY</code> environment variable (default: <code>default_api_key</code>).  For production deployments, always use a secure, randomly generated key.</p>"},{"location":"api-documentation/#authentication-example","title":"Authentication Example","text":"<pre><code>curl -X GET http://localhost:8000/api/v3/health \\\n  -H \"X-API-Key: your_secure_api_key\"\n</code></pre>"},{"location":"api-documentation/#base-url-structure","title":"\ud83c\udf10 Base URL Structure","text":"<p>The API follows a versioned URL structure that automatically matches your data version:</p> <pre><code>http://{host}:{port}/api/{data_version}/\n</code></pre> Parameter Description Default Example <code>host</code> API server host <code>0.0.0.0</code> <code>localhost</code> <code>port</code> API server port <code>8000</code> <code>8080</code> <code>data_version</code> Current data version <code>v3</code> <code>v2</code>, <code>v3</code> <p>Version Synchronization</p> <p>The API version automatically matches your <code>DATA_VERSION</code> environment variable.  When you change data versions, endpoints update accordingly (e.g., <code>/api/v2/predictions</code>).</p>"},{"location":"api-documentation/#endpoints-overview","title":"\ud83d\udcca Endpoints Overview","text":"Endpoint Method Description Rate Limit <code>/predictions</code> POST Single property valuation 100/min <code>/predictions/batch</code> POST Batch property valuation 20/min <code>/model/info</code> GET Model information 200/min <code>/health</code> GET System health check Unlimited"},{"location":"api-documentation/#single-property-valuation","title":"\ud83c\udfe0 Single Property Valuation","text":""},{"location":"api-documentation/#endpoint","title":"Endpoint","text":"POST /api/v3/predictions <p>Generate accurate property valuation using advanced machine learning models trained on comprehensive Chilean real estate market data.</p>"},{"location":"api-documentation/#request-format","title":"Request Format","text":"<pre><code>{\n  \"features\": {\n    \"type\": \"string\",\n    \"sector\": \"string\", \n    \"net_usable_area\": \"number\",\n    \"net_area\": \"number\",\n    \"n_rooms\": \"integer\",\n    \"n_bathroom\": \"integer\",\n    \"latitude\": \"number\",\n    \"longitude\": \"number\"\n  }\n}\n</code></pre>"},{"location":"api-documentation/#required-parameters","title":"Required Parameters","text":"Parameter Type Description Validation <code>type</code> string Property classification <code>departamento</code>, <code>casa</code>, <code>oficina</code> <code>sector</code> string Geographic sector in Santiago Valid Santiago sector name <code>net_usable_area</code> number Usable floor area (m\u00b2) &gt; 0, &lt; 1000 <code>net_area</code> number Total property area (m\u00b2) &gt; 0, &lt; 2000 <code>n_rooms</code> integer Number of bedrooms 0-10 <code>n_bathroom</code> integer Number of bathrooms 0-10 <code>latitude</code> number Geographic coordinate -90 to 90 <code>longitude</code> number Geographic coordinate -180 to 180"},{"location":"api-documentation/#example-request","title":"Example Request","text":"<pre><code>curl -X POST http://localhost:8000/api/v3/predictions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-API-Key: default_api_key\" \\\n  -d '{\n    \"features\": {\n      \"type\": \"departamento\",\n      \"sector\": \"las condes\", \n      \"net_usable_area\": 120.5,\n      \"net_area\": 150.0,\n      \"n_rooms\": 3,\n      \"n_bathroom\": 2,\n      \"latitude\": -33.4172,\n      \"longitude\": -70.5476\n    }\n  }'\n</code></pre>"},{"location":"api-documentation/#response-format","title":"Response Format","text":"<pre><code>{\n  \"prediction\": 185000000,\n  \"prediction_time\": 0.0234,\n  \"model_version\": \"best_rmse_pipeline\"\n}\n</code></pre>"},{"location":"api-documentation/#response-fields","title":"Response Fields","text":"Field Type Description <code>prediction</code> number Property valuation in Chilean Pesos (CLP) <code>prediction_time</code> number Processing time in seconds <code>model_version</code> string Model version identifier"},{"location":"api-documentation/#batch-property-valuation","title":"\ud83c\udfd8\ufe0f Batch Property Valuation","text":""},{"location":"api-documentation/#endpoint_1","title":"Endpoint","text":"POST /api/v3/predictions/batch <p>Process multiple property valuations in a single request for improved efficiency.</p>"},{"location":"api-documentation/#request-format_1","title":"Request Format","text":"<pre><code>{\n  \"properties\": [\n    {\n      \"features\": {\n        \"type\": \"departamento\",\n        \"sector\": \"las condes\",\n        \"net_usable_area\": 120.5,\n        \"net_area\": 150.0,\n        \"n_rooms\": 3,\n        \"n_bathroom\": 2,\n        \"latitude\": -33.4172,\n        \"longitude\": -70.5476\n      }\n    },\n    {\n      \"features\": {\n        \"type\": \"casa\",\n        \"sector\": \"providencia\",\n        \"net_usable_area\": 200.0,\n        \"net_area\": 250.0,\n        \"n_rooms\": 4,\n        \"n_bathroom\": 3,\n        \"latitude\": -33.4298,\n        \"longitude\": -70.6345\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"api-documentation/#batch-limits","title":"Batch Limits","text":"<p>Batch Processing Limits</p> <ul> <li>Maximum properties per request: 100</li> <li>Request timeout: 30 seconds</li> <li>Rate limit: 20 requests per minute</li> </ul>"},{"location":"api-documentation/#example-request_1","title":"Example Request","text":"<pre><code>curl -X POST http://localhost:8000/api/v3/predictions/batch \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-API-Key: default_api_key\" \\\n  -d '{\n    \"properties\": [\n      {\n        \"features\": {\n          \"type\": \"departamento\",\n          \"sector\": \"las condes\",\n          \"net_usable_area\": 120.5,\n          \"net_area\": 150.0,\n          \"n_rooms\": 3,\n          \"n_bathroom\": 2,\n          \"latitude\": -33.4172,\n          \"longitude\": -70.5476\n        }\n      },\n      {\n        \"features\": {\n          \"type\": \"casa\", \n          \"sector\": \"providencia\",\n          \"net_usable_area\": 200.0,\n          \"net_area\": 250.0,\n          \"n_rooms\": 4,\n          \"n_bathroom\": 3,\n          \"latitude\": -33.4298,\n          \"longitude\": -70.6345\n        }\n      }\n    ]\n  }'\n</code></pre>"},{"location":"api-documentation/#response-format_1","title":"Response Format","text":"<pre><code>{\n  \"predictions\": [\n    {\n      \"prediction\": 185000000,\n      \"prediction_time\": 0.0234,\n      \"model_version\": \"best_rmse_pipeline\"\n    },\n    {\n      \"prediction\": 320000000,\n      \"prediction_time\": 0.0245,\n      \"model_version\": \"best_rmse_pipeline\"\n    }\n  ],\n  \"total_time\": 0.0479,\n  \"processed_count\": 2\n}\n</code></pre>"},{"location":"api-documentation/#model-information","title":"\ud83d\udccb Model Information","text":""},{"location":"api-documentation/#endpoint_2","title":"Endpoint","text":"GET /api/v3/model/info <p>Retrieve comprehensive information about the currently loaded model, including metadata, features, and performance metrics.</p>"},{"location":"api-documentation/#example-request_2","title":"Example Request","text":"<pre><code>curl -X GET http://localhost:8000/api/v3/model/info \\\n  -H \"X-API-Key: default_api_key\"\n</code></pre>"},{"location":"api-documentation/#response-format_2","title":"Response Format","text":"<pre><code>{\n  \"model_version\": \"best_rmse_pipeline\",\n  \"data_version\": \"v3\",\n  \"model_type\": \"gradient_boosting\",\n  \"training_date\": \"2024-01-15T14:30:45Z\",\n  \"features\": [\n    \"type\",\n    \"sector\", \n    \"net_usable_area\",\n    \"net_area\",\n    \"n_rooms\",\n    \"n_bathroom\",\n    \"latitude\",\n    \"longitude\"\n  ],\n  \"metrics\": {\n    \"rmse\": 15234567.89,\n    \"mae\": 9876543.21,\n    \"r2\": 0.87\n  },\n  \"training_samples\": 50000,\n  \"validation_samples\": 12500\n}\n</code></pre>"},{"location":"api-documentation/#response-fields_1","title":"Response Fields","text":"Field Type Description <code>model_version</code> string Model version identifier <code>data_version</code> string Data version used for training <code>model_type</code> string Algorithm type (gradient_boosting, random_forest, etc.) <code>training_date</code> string ISO 8601 timestamp of training completion <code>features</code> array List of input features <code>metrics</code> object Model performance metrics <code>training_samples</code> integer Number of training samples <code>validation_samples</code> integer Number of validation samples"},{"location":"api-documentation/#health-check","title":"\ud83c\udfe5 Health Check","text":""},{"location":"api-documentation/#endpoint_3","title":"Endpoint","text":"GET /api/v3/health <p>Monitor system health and availability status.</p>"},{"location":"api-documentation/#example-request_3","title":"Example Request","text":"<pre><code>curl -X GET http://localhost:8000/api/v3/health \\\n  -H \"X-API-Key: default_api_key\"\n</code></pre>"},{"location":"api-documentation/#response-format_3","title":"Response Format","text":"<pre><code>{\n  \"status\": \"healthy\",\n  \"api_version\": \"1.0.0\",\n  \"model_loaded\": true,\n  \"model_version\": \"best_rmse_pipeline\",\n  \"data_version\": \"v3\",\n  \"uptime\": 3600,\n  \"memory_usage\": {\n    \"used\": \"512MB\",\n    \"available\": \"2GB\"\n  },\n  \"disk_usage\": {\n    \"used\": \"1.2GB\", \n    \"available\": \"10GB\"\n  }\n}\n</code></pre>"},{"location":"api-documentation/#health-status-values","title":"Health Status Values","text":"Status Description <code>healthy</code> All systems operational <code>degraded</code> Some non-critical issues <code>unhealthy</code> Critical issues detected"},{"location":"api-documentation/#error-handling","title":"\u26a0\ufe0f Error Handling","text":"<p>The API returns standard HTTP status codes with detailed error information:</p>"},{"location":"api-documentation/#http-status-codes","title":"HTTP Status Codes","text":"Code Status Description 200 OK Request successful 400 Bad Request Invalid input data 401 Unauthorized Missing or invalid API key 422 Unprocessable Entity Validation errors 429 Too Many Requests Rate limit exceeded 500 Internal Server Error Server-side error"},{"location":"api-documentation/#error-response-format","title":"Error Response Format","text":"<pre><code>{\n  \"error\": \"Validation Error\",\n  \"detail\": \"Invalid property type. Must be one of: departamento, casa, oficina\",\n  \"status_code\": 422,\n  \"timestamp\": \"2024-01-15T14:30:45Z\",\n  \"request_id\": \"req_123456789\"\n}\n</code></pre>"},{"location":"api-documentation/#common-error-examples","title":"Common Error Examples","text":"Invalid API KeyValidation ErrorRate Limit Exceeded <pre><code>{\n  \"error\": \"Unauthorized\",\n  \"detail\": \"Invalid or missing API key\",\n  \"status_code\": 401\n}\n</code></pre> <pre><code>{\n  \"error\": \"Validation Error\",\n  \"detail\": [\n    {\n      \"loc\": [\"body\", \"features\", \"net_usable_area\"],\n      \"msg\": \"ensure this value is greater than 0\",\n      \"type\": \"value_error.number.not_gt\"\n    }\n  ],\n  \"status_code\": 422\n}\n</code></pre> <pre><code>{\n  \"error\": \"Rate Limit Exceeded\",\n  \"detail\": \"Too many requests. Limit: 100 per minute\",\n  \"status_code\": 429,\n  \"retry_after\": 60\n}\n</code></pre>"},{"location":"api-documentation/#rate-limiting","title":"\ud83d\udea6 Rate Limiting","text":"<p>The API implements rate limiting to ensure fair usage and system stability:</p> Endpoint Rate Limit Window <code>/predictions</code> 100 requests 1 minute <code>/predictions/batch</code> 20 requests 1 minute <code>/model/info</code> 200 requests 1 minute <code>/health</code> Unlimited -"},{"location":"api-documentation/#rate-limit-headers","title":"Rate Limit Headers","text":"<pre><code>X-RateLimit-Limit: 100\nX-RateLimit-Remaining: 95\nX-RateLimit-Reset: 1642262400\n</code></pre>"},{"location":"api-documentation/#sdk-and-integration-examples","title":"\ud83d\udd27 SDK and Integration Examples","text":""},{"location":"api-documentation/#python-sdk-example","title":"Python SDK Example","text":"<pre><code>import requests\nimport json\n\nclass PropertyValuationClient:\n    def __init__(self, base_url, api_key):\n        self.base_url = base_url\n        self.headers = {\n            'Content-Type': 'application/json',\n            'X-API-Key': api_key\n        }\n\n    def predict(self, features):\n        response = requests.post(\n            f\"{self.base_url}/api/v3/predictions\",\n            headers=self.headers,\n            json={\"features\": features}\n        )\n        return response.json()\n\n    def batch_predict(self, properties):\n        response = requests.post(\n            f\"{self.base_url}/api/v3/predictions/batch\",\n            headers=self.headers,\n            json={\"properties\": properties}\n        )\n        return response.json()\n\n# Usage\nclient = PropertyValuationClient(\"http://localhost:8000\", \"your_api_key\")\nresult = client.predict({\n    \"type\": \"departamento\",\n    \"sector\": \"las condes\",\n    \"net_usable_area\": 120.5,\n    \"net_area\": 150.0,\n    \"n_rooms\": 3,\n    \"n_bathroom\": 2,\n    \"latitude\": -33.4172,\n    \"longitude\": -70.5476\n})\nprint(f\"Predicted value: ${result['prediction']:,} CLP\")\n</code></pre>"},{"location":"api-documentation/#javascriptnodejs-example","title":"JavaScript/Node.js Example","text":"<pre><code>const axios = require('axios');\n\nclass PropertyValuationClient {\n    constructor(baseUrl, apiKey) {\n        this.baseUrl = baseUrl;\n        this.headers = {\n            'Content-Type': 'application/json',\n            'X-API-Key': apiKey\n        };\n    }\n\n    async predict(features) {\n        try {\n            const response = await axios.post(\n                `${this.baseUrl}/api/v3/predictions`,\n                { features },\n                { headers: this.headers }\n            );\n            return response.data;\n        } catch (error) {\n            throw new Error(`Prediction failed: ${error.response.data.detail}`);\n        }\n    }\n}\n\n// Usage\nconst client = new PropertyValuationClient('http://localhost:8000', 'your_api_key');\nconst result = await client.predict({\n    type: 'departamento',\n    sector: 'las condes',\n    net_usable_area: 120.5,\n    net_area: 150.0,\n    n_rooms: 3,\n    n_bathroom: 2,\n    latitude: -33.4172,\n    longitude: -70.5476\n});\nconsole.log(`Predicted value: $${result.prediction.toLocaleString()} CLP`);\n</code></pre>"},{"location":"api-documentation/#interactive-api-documentation","title":"\ud83d\udcca Interactive API Documentation","text":"<p>For hands-on API exploration, visit our interactive documentation:</p> <ul> <li>Swagger UI: http://localhost:8000/docs</li> <li>ReDoc: http://localhost:8000/redoc</li> </ul> <p>These interfaces provide: - \u2705 Interactive request/response testing - \u2705 Complete schema documentation - \u2705 Authentication testing - \u2705 Response format examples</p>"},{"location":"api-documentation/#monitoring-and-observability","title":"\ud83d\udd0d Monitoring and Observability","text":""},{"location":"api-documentation/#request-logging","title":"Request Logging","text":"<p>All API requests are logged with structured data:</p> <pre><code>{\n  \"timestamp\": \"2024-01-15T14:30:45Z\",\n  \"request_id\": \"req_123456789\",\n  \"method\": \"POST\",\n  \"endpoint\": \"/api/v3/predictions\",\n  \"status_code\": 200,\n  \"response_time\": 0.0234,\n  \"user_agent\": \"PropertyValuationClient/1.0\",\n  \"ip_address\": \"192.168.1.100\"\n}\n</code></pre>"},{"location":"api-documentation/#performance-metrics","title":"Performance Metrics","text":"<p>Monitor API performance through logs:</p> <ul> <li>Response Time: Average &lt; 50ms</li> <li>Throughput: 1000+ requests/minute</li> <li>Error Rate: &lt; 0.1%</li> <li>Availability: 99.9% uptime</li> </ul>"},{"location":"api-documentation/#support","title":"\ud83d\udcde Support","text":"<p>Need help with the API? We're here to assist:</p> <ul> <li>\ud83d\udcd6 Documentation: Complete API reference and guides</li> <li>\ud83d\udc1b GitHub Issues: Bug reports and feature requests</li> <li>\ud83d\udce7 Email: api-support@property-valuation.com</li> <li>\ud83d\udcac Community: Join our developer community</li> </ul> <p>Build amazing applications with our Property Valuation API!</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Welcome to the Property Valuation ML System! This guide will help you get up and running quickly with our enterprise-grade machine learning platform.</p>"},{"location":"getting-started/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<p>Before you begin, ensure your system meets these requirements:</p> <p>System Requirements</p> <ul> <li>Python: 3.8 or higher</li> <li>Docker: Latest version (recommended)</li> <li>Memory: Minimum 4GB RAM</li> <li>Storage: 2GB free space</li> <li>OS: Linux, macOS, or Windows</li> </ul>"},{"location":"getting-started/#required-tools","title":"Required Tools","text":"EssentialRecommended <ul> <li>Python 3.8+</li> <li>Git</li> </ul> <ul> <li>Docker Desktop</li> <li>VS Code with Python extension</li> <li>Postman for API testing</li> </ul>"},{"location":"getting-started/#quick-installation","title":"\ud83d\ude80 Quick Installation","text":"<p>Choose your preferred installation method:</p>"},{"location":"getting-started/#option-a-docker-setup-recommended","title":"Option A: Docker Setup (Recommended)","text":"<p>Docker provides the fastest and most reliable setup experience:</p> <pre><code># 1. Clone the repository\ngit clone https://github.com/jarb29/property-valuation\ncd property-valuation\n\n# 2. Prepare your data\nmkdir -p data/v1\n# Copy your train.csv and test.csv files to data/v1/\n\n# 3. Create minimal .env file\necho \"API_HOST=0.0.0.0\" &gt; .env\necho \"API_PORT=8000\" &gt;&gt; .env\n\n# 4. Run the ML pipeline\ndocker-compose --profile pipeline up pipeline\n\n# 5. Start the API service\ndocker-compose up api\n\n# 6. Verify installation\ncurl http://localhost:8000/api/v1/health\n</code></pre> <p>Docker Benefits</p> <ul> <li>\u2705 No dependency conflicts</li> <li>\u2705 Consistent environment</li> <li>\u2705 Production-ready configuration</li> <li>\u2705 Easy scaling and deployment</li> </ul>"},{"location":"getting-started/#option-b-local-python-setup","title":"Option B: Local Python Setup","text":"<p>For development and customization:</p> <pre><code># 1. Clone and navigate\ngit clone https://github.com/jarb29/property-valuation\ncd property-valuation\n\n# 2. Prepare your data\nmkdir -p data/v1\n# Copy your train.csv and test.csv files to data/v1/\n\n# 3. Create virtual environment\npython -m venv .venv\n\n# 4. Activate environment\n# On macOS/Linux:\nsource .venv/bin/activate\n# On Windows:\n.venv\\Scripts\\activate\n\n# 5. Install dependencies\npip install -r requirements.txt\n\n# 6. Configure environment\ncp .env.example .env\n# Edit .env to set DATA_VERSION=v1\n\n# 7. Run the ML pipeline\npython scripts/pipeline.py\n\n# 8. Start the API\npython scripts/run_api.py\n</code></pre>"},{"location":"getting-started/#configuration","title":"\ud83d\udd27 Configuration","text":""},{"location":"getting-started/#environment-variables","title":"Environment Variables","text":"<p>The system uses environment variables for configuration. Key settings:</p> Variable Description Default Example <code>DATA_VERSION</code> Data version to use <code>v1</code> <code>v1</code>, <code>v2</code>, <code>v3</code> <code>MODEL_METRIC</code> Model selection metric <code>rmse</code> <code>mae</code>, <code>r2</code> <code>API_HOST</code> API server host <code>0.0.0.0</code> <code>localhost</code> <code>API_PORT</code> API server port <code>8000</code> <code>8080</code> <code>API_KEY</code> Authentication key <code>default_api_key</code> <code>your_secure_key</code>"},{"location":"getting-started/#sample-configuration","title":"Sample Configuration","text":"<p>Create your <code>.env</code> file:</p> <pre><code># Data Configuration\nDATA_VERSION=v1\nMODEL_VERSION=v1\nMODEL_METRIC=rmse\nMODEL_LOAD_TARGET=pipeline\n\n# API Configuration\nAPI_HOST=0.0.0.0\nAPI_PORT=8000\nAPI_KEY=your_secure_api_key\nAPI_DEBUG=False\n\n# Logging Configuration\nLOG_LEVEL=INFO\n</code></pre>"},{"location":"getting-started/#model-configuration-details","title":"Model Configuration Details","text":"<p>The system uses these key variables (defined in <code>src/config</code>) for intelligent model selection:</p> Variable Purpose Options Example <code>API_KEY</code> API authentication Any string <code>\"my_secure_key\"</code> <code>MODEL_VERSION</code> Model version to load Defaults to <code>DATA_VERSION</code> <code>v1</code>, <code>v2</code>, <code>v3</code> <code>MODEL_METRIC</code> Best model selection criteria <code>rmse</code>, <code>mae</code>, <code>mape</code> <code>rmse</code> <code>MODEL_LOAD_TARGET</code> Model source location <code>pipeline</code>, <code>jupyter</code> <code>pipeline</code> <p>How Model Selection Works:</p> <ol> <li>Training Phase: Multiple models are trained and saved with performance metrics</li> <li>Selection Phase: System chooses the best model based on <code>MODEL_METRIC</code></li> <li>Loading Phase: API loads the selected model from <code>MODEL_LOAD_TARGET</code> location</li> <li>Versioning: All artifacts are saved with version numbers for traceability</li> </ol> <p>Example Workflow:</p> <pre><code># Train models with different configurations\nMODEL_METRIC=rmse python scripts/pipeline.py  # Selects best RMSE model\nMODEL_METRIC=mae python scripts/pipeline.py   # Selects best MAE model\n\n# API automatically loads the best model based on your configuration\nMODEL_LOAD_TARGET=pipeline MODEL_METRIC=rmse python scripts/run_api.py\n</code></pre> <p>Critical: Data Version Selection</p> <p>Always specify your data version before training or running the API: <pre><code>export DATA_VERSION=v1  # \u26a0\ufe0f REQUIRED: Choose v1, v2, v3, etc.\n</code></pre> This determines which dataset and models the system will use.</p>"},{"location":"getting-started/#verify-your-installation","title":"\ud83e\uddea Verify Your Installation","text":""},{"location":"getting-started/#1-health-check","title":"1. Health Check","text":"<p>Test that the API is running:</p> <pre><code>curl -X GET http://localhost:8000/api/v1/health \\\n  -H \"X-API-Key: default_api_key\"\n</code></pre> <p>Expected response:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"api_version\": \"1.0.0\",\n  \"model_loaded\": true,\n  \"model_version\": \"best_rmse_pipeline\",\n  \"data_version\": \"v3\",\n  \"uptime\": 60\n}\n</code></pre>"},{"location":"getting-started/#2-model-information","title":"2. Model Information","text":"<p>Check the loaded model:</p> <pre><code>curl -X GET http://localhost:8000/api/v1/model/info \\\n  -H \"X-API-Key: default_api_key\"\n</code></pre>"},{"location":"getting-started/#3-sample-prediction","title":"3. Sample Prediction","text":"<p>Make your first prediction:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/predictions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-API-Key: default_api_key\" \\\n  -d '{\n    \"features\": {\n      \"type\": \"departamento\",\n      \"sector\": \"las condes\",\n      \"net_usable_area\": 120.5,\n      \"net_area\": 150.0,\n      \"n_rooms\": 3,\n      \"n_bathroom\": 2,\n      \"latitude\": -33.4172,\n      \"longitude\": -70.5476\n    }\n  }'\n</code></pre> <p>Expected response:</p> <pre><code>{\n  \"prediction\": 185000000,\n  \"prediction_time\": 0.0234,\n  \"model_version\": \"best_rmse_pipeline\"\n}\n</code></pre>"},{"location":"getting-started/#your-first-workflow","title":"\ud83c\udfaf Your First Workflow","text":"<p>Now that everything is set up, let's walk through a complete workflow:</p>"},{"location":"getting-started/#step-1-explore-the-data","title":"Step 1: Explore the Data","text":"<pre><code># Check available data versions\nls data/\n\n# View sample data\nhead -5 data/v1/train.csv\n</code></pre>"},{"location":"getting-started/#step-2-train-a-model","title":"Step 2: Train a Model","text":"<pre><code># Run the ML pipeline with default settings\ndocker-compose --profile pipeline up pipeline\n\n# Or with custom configuration\nDATA_VERSION=v1 MODEL_METRIC=mae docker-compose --profile pipeline up pipeline\n</code></pre>"},{"location":"getting-started/#step-3-start-the-api","title":"Step 3: Start the API","text":"<p>After training, start the API server:</p> <pre><code># Start the API service\ndocker-compose up api\n\n# Or use a different port if 8000 is busy\nAPI_PORT=8080 docker-compose up api\n</code></pre> <p>Verify the API is running:</p> <pre><code># Check API health\ncurl http://localhost:8000/api/v1/health\n\n# Expected response: {\"status\": \"healthy\", \"model_loaded\": true}\n</code></pre>"},{"location":"getting-started/#step-4-make-predictions","title":"Step 4: Make Predictions","text":"<p>Use the API to make predictions for different property types:</p> ApartmentHouse <pre><code>{\n  \"features\": {\n    \"type\": \"departamento\",\n    \"sector\": \"providencia\",\n    \"net_usable_area\": 85.0,\n    \"net_area\": 100.0,\n    \"n_rooms\": 2,\n    \"n_bathroom\": 1,\n    \"latitude\": -33.4298,\n    \"longitude\": -70.6345\n  }\n}\n</code></pre> <pre><code>{\n  \"features\": {\n    \"type\": \"casa\",\n    \"sector\": \"las condes\",\n    \"net_usable_area\": 200.0,\n    \"net_area\": 300.0,\n    \"n_rooms\": 4,\n    \"n_bathroom\": 3,\n    \"latitude\": -33.4172,\n    \"longitude\": -70.5476\n  }\n}\n</code></pre>"},{"location":"getting-started/#step-5-batch-processing","title":"Step 5: Batch Processing","text":"<p>For multiple properties:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/predictions/batch \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-API-Key: default_api_key\" \\\n  -d '{\n    \"properties\": [\n      {\"features\": {...}},\n      {\"features\": {...}}\n    ]\n  }'\n</code></pre>"},{"location":"getting-started/#development-tools","title":"\ud83d\udd0d Development Tools","text":""},{"location":"getting-started/#api-documentation","title":"API Documentation","text":"<p>Access interactive API documentation:</p> <ul> <li>Swagger UI: http://localhost:8000/docs</li> <li>ReDoc: http://localhost:8000/redoc</li> </ul>"},{"location":"getting-started/#monitoring-and-logs","title":"Monitoring and Logs","text":"<p>Monitor your system:</p> <pre><code># View API logs\ntail -f outputs/predictions/api.log\n\n# View pipeline logs\ntail -f outputs/pipeline/logs/pipeline.log\n\n# Docker logs\ndocker-compose logs -f api\n</code></pre>"},{"location":"getting-started/#development-mode","title":"Development Mode","text":"<p>For active development:</p> <pre><code># Start with hot reload\npython scripts/run_api.py --reload\n\n# Or with Docker\ndocker-compose --profile dev up api-dev\n</code></pre>"},{"location":"getting-started/#troubleshooting","title":"\ud83d\udea8 Troubleshooting","text":""},{"location":"getting-started/#common-issues","title":"Common Issues","text":"<p>Port Already in Use</p> <p>Problem: Port 8000 is already in use (Docker error: \"port is already allocated\")</p> <p>Solutions: <pre><code># Option 1: Use a different port (recommended)\nAPI_PORT=8080 docker-compose up api\n\n# Option 2: Kill the process using port 8000\nlsof -ti:8000 | xargs kill -9\n\n# Option 3: Stop all Docker containers first\ndocker-compose down\n```ker-compose down\n\n# Option 4: Check what's using the port\nlsof -i :8000\n\n# Option 5: For Python API (auto-finds available port)\npython scripts/run_api.py --auto-port\n</code></pre></p> <p>Smart Port Detection</p> <p>The Python API script automatically finds available ports and shows helpful messages: <pre><code>WARNING: Port 8000 is already in use. Using port 8001 instead.\n</code></pre></p> <p>Model Not Found</p> <p>Problem: No model file found</p> <pre><code>**Solution**:\n```bash\n# Train a model first\npython scripts/pipeline.py\n# Or check if model exists\nls outputs/pipeline/models/\n```\n</code></pre> <p>Permission Denied</p> <p>Problem: Docker permission issues</p> <pre><code>**Solution**:\n```bash\n# Add user to docker group (Linux)\nsudo usermod -aG docker $USER\n# Or run with sudo\nsudo docker-compose up api\n```\n</code></pre>"},{"location":"getting-started/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ol> <li>Check the logs for detailed error messages</li> <li>Verify environment variables are set correctly</li> <li>Ensure all dependencies are installed</li> <li>Check Docker status if using containers</li> </ol>"},{"location":"getting-started/#next-steps","title":"\ud83c\udf89 Next Steps","text":"<p>Congratulations! You now have a working Property Valuation ML System. Here's what to explore next:</p> Next Step Description Link API Deep Dive Learn all API endpoints and features API Documentation System Architecture Understand the complete system design User Manual Custom Models Train models with your own data User Manual - Training Production Deployment Deploy to production environments User Manual - Deployment"},{"location":"getting-started/#support","title":"\ud83d\udcde Support","text":"<p>Need help? We're here for you:</p> <ul> <li>\ud83d\udcd6 Documentation: Complete guides and references</li> <li>\ud83d\udc1b GitHub Issues: Bug reports and feature requests</li> <li>\ud83d\udce7 Email: team@property-valuation.com</li> <li>\ud83d\udcac Community: Join our developer community</li> </ul> <p>Ready to build amazing property valuation applications!</p>"},{"location":"installation-guide/","title":"Installation Guide","text":"<p>This guide provides detailed instructions for installing and configuring the Property Valuation ML System in different environments.</p>"},{"location":"installation-guide/#system-requirements","title":"System Requirements","text":""},{"location":"installation-guide/#minimum-requirements","title":"Minimum Requirements","text":"<ul> <li>CPU: 2 cores</li> <li>RAM: 4GB</li> <li>Disk: 10GB free space</li> <li>Operating System: Linux, macOS, or Windows 10+</li> <li>Python 3.8+</li> <li>Docker 20.10+ and Docker Compose 2.0+ (for containerized deployment)</li> </ul>"},{"location":"installation-guide/#recommended-requirements","title":"Recommended Requirements","text":"<ul> <li>CPU: 4+ cores</li> <li>RAM: 8GB+</li> <li>Disk: 20GB+ free space</li> <li>SSD storage for improved performance</li> </ul>"},{"location":"installation-guide/#installation-methods","title":"Installation Methods","text":""},{"location":"installation-guide/#method-1-docker-installation-recommended","title":"Method 1: Docker Installation (Recommended)","text":"<p>Docker provides the easiest and most consistent way to deploy the system across different environments.</p>"},{"location":"installation-guide/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install Docker</li> <li>Install Docker Compose</li> </ol>"},{"location":"installation-guide/#steps","title":"Steps","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/jarb29/property-valuation\ncd property-valuation\n</code></pre></p> </li> <li> <p>Build the Docker images:    <pre><code>docker-compose build\n</code></pre></p> </li> <li> <p>Start the services:    <pre><code># Start the API service\ndocker-compose up api\n\n# Or start in detached mode\ndocker-compose up -d api\n</code></pre></p> </li> <li> <p>Verify the installation:    <pre><code>curl http://localhost:8000/api/v1/health\n</code></pre></p> </li> </ol>"},{"location":"installation-guide/#docker-compose-profiles","title":"Docker Compose Profiles","text":"<p>The system includes several Docker Compose profiles for different use cases:</p> <ul> <li> <p>Default: Runs the API service   <pre><code>docker-compose up api\n</code></pre></p> </li> <li> <p>Development: Runs the API with hot reload for development   <pre><code>docker-compose --profile dev up api-dev\n</code></pre></p> </li> <li> <p>Pipeline: Runs the ML pipeline for training models   <pre><code>docker-compose --profile pipeline up pipeline\n</code></pre></p> </li> </ul>"},{"location":"installation-guide/#method-2-local-python-installation","title":"Method 2: Local Python Installation","text":"<p>For development or when Docker is not available, you can install the system directly on your machine.</p>"},{"location":"installation-guide/#prerequisites_1","title":"Prerequisites","text":"<ol> <li>Install Python 3.8+</li> <li>Install pip</li> <li>(Optional) Install virtualenv</li> </ol>"},{"location":"installation-guide/#steps_1","title":"Steps","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/jarb29/property-valuation\ncd property-valuation\n</code></pre></p> </li> <li> <p>Create and activate a virtual environment (recommended):    <pre><code>python -m venv .venv\n\n# On Linux/macOS\nsource .venv/bin/activate\n\n# On Windows\n.venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install dependencies:    <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> <li> <p>Set up environment variables:    <pre><code>cp .env.example .env\n# Edit .env with your configuration\n</code></pre></p> </li> <li> <p>Run the API:    <pre><code>python scripts/run_api.py\n</code></pre></p> </li> <li> <p>Verify the installation:    <pre><code>curl http://localhost:8000/api/v1/health\n</code></pre></p> </li> </ol>"},{"location":"installation-guide/#configuration","title":"Configuration","text":""},{"location":"installation-guide/#environment-variables","title":"Environment Variables","text":"<p>The system is configured using environment variables. You can set these in a <code>.env</code> file or directly in your environment.</p>"},{"location":"installation-guide/#core-settings","title":"Core Settings","text":"Variable Description Default Notes <code>DATA_VERSION</code> Version of data to use <code>v1</code> Controls which data folder is used (<code>data/v1</code>) <code>MODEL_VERSION</code> Version of model to use Same as <code>DATA_VERSION</code> Used in model filenames (<code>model_v1.pkl</code>) <code>MODEL_METRIC</code> Metric for model selection <code>rmse</code> Options: <code>rmse</code>, <code>mae</code>, <code>r2</code> <code>MODEL_LOAD_TARGET</code> Source of models <code>pipeline</code> Options: <code>pipeline</code>, <code>jupyter</code>"},{"location":"installation-guide/#api-settings","title":"API Settings","text":"Variable Description Default <code>API_HOST</code> Host for the API server <code>0.0.0.0</code> <code>API_PORT</code> Port for the API server <code>8000</code> <code>API_WORKERS</code> Number of worker processes <code>1</code> <code>API_DEBUG</code> Enable debug mode <code>False</code> <code>API_KEY</code> API authentication key <code>default_api_key</code>"},{"location":"installation-guide/#logging-settings","title":"Logging Settings","text":"Variable Description Default <code>LOG_LEVEL</code> Logging level <code>INFO</code> <code>LOG_MAX_BYTES</code> Maximum log file size <code>10485760</code> (10MB) <code>LOG_BACKUP_COUNT</code> Number of backup log files <code>5</code>"},{"location":"installation-guide/#configuration-file","title":"Configuration File","text":"<p>For more advanced configuration, you can modify the <code>src/config.py</code> file. This file contains default values for all settings and loads environment variables.</p>"},{"location":"installation-guide/#directory-structure","title":"Directory Structure","text":"<p>Understanding the directory structure helps with configuration:</p> <pre><code>\u251c\u2500\u2500 data/               # Version-controlled datasets\n\u2502   \u251c\u2500\u2500 v1/             # Data version 1 (train.csv, test.csv)\n\u2502   \u251c\u2500\u2500 v2/             # Data version 2\n\u2502   \u2514\u2500\u2500 v3/             # Data version 3 (current default)\n\u251c\u2500\u2500 docs/               # Documentation files\n\u251c\u2500\u2500 notebooks/          # Jupyter notebooks for exploration\n\u251c\u2500\u2500 outputs/            # Model outputs, logs, and schemas\n\u2502   \u251c\u2500\u2500 pipeline/       # Pipeline-generated artifacts\n\u2502   \u2502   \u251c\u2500\u2500 models/     # Trained models (model_v3.pkl)\n\u2502   \u2502   \u251c\u2500\u2500 schema/     # Data schemas (v3_schema_train.json)\n\u2502   \u2502   \u251c\u2500\u2500 data/       # Processed data files\n\u2502   \u2502   \u2514\u2500\u2500 logs/       # Pipeline execution logs\n\u2502   \u251c\u2500\u2500 jupyter/        # Notebook-generated artifacts\n\u2502   \u2514\u2500\u2500 predictions/    # API prediction logs\n\u251c\u2500\u2500 scripts/            # Execution scripts\n\u251c\u2500\u2500 src/                # Source code\n\u2502   \u251c\u2500\u2500 api/            # API implementation\n\u2502   \u251c\u2500\u2500 data/           # Data processing modules\n\u2502   \u251c\u2500\u2500 models/         # ML model implementations\n\u2502   \u251c\u2500\u2500 pipeline/       # Pipeline components\n\u2502   \u2514\u2500\u2500 utils/          # Utility functions\n\u2514\u2500\u2500 tests/              # Test suite\n</code></pre>"},{"location":"installation-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation-guide/#common-issues","title":"Common Issues","text":""},{"location":"installation-guide/#docker-issues","title":"Docker Issues","text":"<ul> <li>Error: Cannot connect to the Docker daemon</li> <li>Make sure Docker is running</li> <li> <p>Try restarting the Docker service</p> </li> <li> <p>Error: Port already in use</p> </li> <li>Change the port in the <code>.env</code> file or use the <code>-p</code> flag with Docker</li> </ul>"},{"location":"installation-guide/#python-issues","title":"Python Issues","text":"<ul> <li>Error: Module not found</li> <li>Make sure you've installed all dependencies: <code>pip install -r requirements.txt</code></li> <li> <p>Check that you're in the correct directory</p> </li> <li> <p>Error: Permission denied</p> </li> <li>Check file permissions for scripts and data directories</li> <li>Try running with sudo (Linux/macOS) or as administrator (Windows)</li> </ul>"},{"location":"installation-guide/#model-issues","title":"Model Issues","text":"<ul> <li>Error: Model file not found</li> <li>Run the pipeline to generate the model: <code>python scripts/pipeline.py</code></li> <li>Check that the <code>DATA_VERSION</code> and <code>MODEL_VERSION</code> are set correctly</li> </ul>"},{"location":"installation-guide/#logs","title":"Logs","text":"<p>Check the log files for detailed error information:</p> <ul> <li>API logs: <code>outputs/predictions/api.log</code></li> <li>Pipeline logs: <code>outputs/pipeline/logs/pipeline.log</code></li> </ul>"},{"location":"installation-guide/#updating","title":"Updating","text":"<p>To update the system to the latest version:</p> <ol> <li> <p>Pull the latest changes:    <pre><code>git pull origin main\n</code></pre></p> </li> <li> <p>Rebuild Docker images (if using Docker):    <pre><code>docker-compose build\n</code></pre></p> </li> <li> <p>Restart the services:    <pre><code>docker-compose down\ndocker-compose up -d api\n</code></pre></p> </li> </ol>"},{"location":"installation-guide/#next-steps","title":"Next Steps","text":"<p>After installation, you might want to:</p> <ul> <li>Read the Getting Started Guide for a quick introduction</li> <li>Explore the API Documentation for details on available endpoints</li> <li>Check the User Manual for in-depth usage instructions</li> </ul>"},{"location":"user-manual/","title":"User Manual","text":"<p>Comprehensive guide to the Property Valuation ML System - from basic usage to advanced configuration.</p>"},{"location":"user-manual/#system-overview","title":"\ud83c\udfd7\ufe0f System Overview","text":"<p>The Property Valuation ML System is an enterprise-grade machine learning platform for accurate real estate property valuation in the Chilean market.</p>"},{"location":"user-manual/#architecture","title":"Architecture","text":"<pre><code>flowchart TD\n    subgraph DataLayer [\"Data Layer\"]\n        A[Raw Data Sources] --&gt; B[Data Versioning System]\n        B --&gt; C[Data Validation &amp; Schema]\n    end\n\n    subgraph MLPipeline [\"ML Pipeline\"]\n        D[Feature Engineering]\n        E[Model Training]\n        F[Model Evaluation]\n        G[Model Registry]\n        D --&gt; E\n        E --&gt; F\n        F --&gt; G\n    end\n\n    subgraph APILayer [\"API Layer\"]\n        H[Model Loading]\n        I[REST API Endpoints]\n        J[Response Validation]\n        H --&gt; I\n        I --&gt; J\n    end\n\n    subgraph Infrastructure [\"Infrastructure\"]\n        K[Docker Containers]\n        L[Logging &amp; Monitoring]\n        M[Authentication]\n    end\n\n    subgraph ClientApps [\"Client Applications\"]\n        N[Web Applications]\n        O[Mobile Apps]\n        P[Third-party Integrations]\n    end\n\n    C --&gt; D\n    G --&gt; H\n    K --&gt; I\n    L --&gt; I\n    M --&gt; I\n    I --&gt; N\n    I --&gt; O\n    I --&gt; P</code></pre>"},{"location":"user-manual/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"user-manual/#training-models","title":"Training Models","text":"<pre><code># Train models\npython scripts/pipeline.py\n\n# Docker training\ndocker-compose --profile pipeline up pipeline\n</code></pre>"},{"location":"user-manual/#running-the-api","title":"Running the API","text":"<pre><code># Development\npython scripts/run_api.py --reload\n\n# Production\ndocker-compose up api\n</code></pre>"},{"location":"user-manual/#data-versioning-system","title":"\ud83d\udcca Data Versioning System","text":"<p>The system uses a sophisticated versioning mechanism for complete traceability:</p>"},{"location":"user-manual/#how-versioning-works","title":"How Versioning Works","text":"<pre><code>DATA_VERSION (e.g., v3)\n     \u2502\n     \u251c\u2500\u2500\u2500 Data paths: data/v3/train.csv, data/v3/test.csv\n     \u2502\n     \u251c\u2500\u2500\u2500 Sub-versions: v3.1, v3.2, v3.3, v3.4, v3.5, v3.6\n     \u2502     \u2502\n     \u2502     \u251c\u2500\u2500\u2500 Pipeline: outputs/pipeline/models/v3.4_gradient_boosting.pkl\n     \u2502     \u2514\u2500\u2500\u2500 Jupyter: outputs/jupyter/models/v3.3_gradient_boosting.pkl\n     \u2502\n     \u2514\u2500\u2500\u2500 API endpoints: /api/v3/predictions\n</code></pre>"},{"location":"user-manual/#file-system-flow","title":"File System Flow","text":"<p>Data Processing Workflow</p> <p>The system follows a clear data flow from input to API predictions:</p>"},{"location":"user-manual/#1-input-data","title":"1. Input Data","text":"<pre><code>\ud83d\udcc1 data/v1/\n   \u251c\u2500\u2500 \ud83d\udcc4 train.csv     (Training dataset)\n   \u2514\u2500\u2500 \ud83d\udcc4 test.csv      (Testing dataset)\n</code></pre>"},{"location":"user-manual/#2-processing-options","title":"2. Processing Options","text":"Pipeline (Production)Jupyter (Research) <pre><code>python scripts/pipeline.py\n# Generates: outputs/pipeline/\n</code></pre> <pre><code>jupyter notebook notebooks/\n# Generates: outputs/jupyter/\n</code></pre>"},{"location":"user-manual/#3-generated-outputs","title":"3. Generated Outputs","text":"<p>Pipeline Outputs (Production-ready): <pre><code>\ud83d\udcc1 outputs/pipeline/\n   \u251c\u2500\u2500 \ud83e\udd16 models/\n   \u2502   \u2514\u2500\u2500 v1.4_gradient_boosting.pkl\n   \u251c\u2500\u2500 \ud83d\udccb schema/\n   \u2502   \u2514\u2500\u2500 v1.4_schema_train.json\n   \u2514\u2500\u2500 \ud83d\udcca data/\n       \u2514\u2500\u2500 v1.4_data_clean.csv\n</code></pre></p> <p>Jupyter Outputs (Research): <pre><code>\ud83d\udcc1 outputs/jupyter/\n   \u251c\u2500\u2500 \ud83e\udd16 models/\n   \u2502   \u2514\u2500\u2500 v1.3_gradient_boosting.pkl\n   \u2514\u2500\u2500 \ud83d\udccb schema/\n       \u2514\u2500\u2500 v1.3_schema_analysis.json\n</code></pre></p>"},{"location":"user-manual/#4-api-service-flow","title":"4. API Service Flow","text":"<pre><code>\ud83c\udfaf Model Selection\n    \u2193\n\ud83d\udce5 Model Loading (from pipeline/ or jupyter/)\n    \u2193\n\ud83d\udd2e Predictions\n    \u2193\n\ud83d\udcdd Logging (to predictions/)\n</code></pre>"},{"location":"user-manual/#5-runtime-logs","title":"5. Runtime Logs","text":"<pre><code>\ud83d\udcc1 outputs/predictions/\n   \u251c\u2500\u2500 \ud83d\udcca api.log       (API access logs)\n   \u2514\u2500\u2500 \u274c error.log     (Error tracking)\n</code></pre>"},{"location":"user-manual/#file-structure","title":"File Structure","text":"<pre><code>outputs/\n\u251c\u2500\u2500 pipeline/                    # Production outputs\n\u2502   \u251c\u2500\u2500 models/v3.4_gradient_boosting_property_valuation.pkl\n\u2502   \u251c\u2500\u2500 schema/v3.4_schema_train.json\n\u2502   \u2514\u2500\u2500 data/v3.4_data_clean.csv\n\u251c\u2500\u2500 jupyter/                     # Research outputs\n\u2502   \u251c\u2500\u2500 models/v3.3_gradient_boosting_property_valuation.pkl\n\u2502   \u2514\u2500\u2500 schema/v3.3_schema_analysis.json\n\u2514\u2500\u2500 predictions/                 # API logs\n    \u251c\u2500\u2500 api.log\n    \u2514\u2500\u2500 error.log\n</code></pre>"},{"location":"user-manual/#model-management","title":"\ud83e\udd16 Model Management","text":""},{"location":"user-manual/#model-metadata","title":"Model Metadata","text":"<p>Each model includes comprehensive metadata:</p> <pre><code>{\n  \"model_type\": \"gradient_boosting\",\n  \"features\": [\"type\", \"sector\", \"net_usable_area\", \"net_area\", \"n_rooms\", \"n_bathroom\", \"latitude\", \"longitude\"],\n  \"evaluation_metrics\": {\n    \"rmse\": 5710.23,\n    \"mae\": 2624.52,\n    \"mape\": 0.467\n  },\n  \"training_data_shape\": [15352, 9],\n  \"timestamp\": \"2025-08-02T22:05:21.892530\"\n}\n</code></pre>"},{"location":"user-manual/#model-selection","title":"Model Selection","text":"Metric Description Use Case RMSE Root Mean Square Error General accuracy (default) MAE Mean Absolute Error Robust to outliers MAPE Mean Absolute Percentage Error Relative accuracy"},{"location":"user-manual/#data-validation","title":"\ud83d\udccb Data Validation","text":""},{"location":"user-manual/#schema-structure","title":"Schema Structure","text":"<p>The system validates data using comprehensive schemas:</p> <pre><code>{\n  \"dataset_name\": \"train_data\",\n  \"shape\": {\"rows\": 15352, \"columns\": 9},\n  \"columns\": {\n    \"type\": {\n      \"categorical\": {\n        \"unique_values_list\": [\"departamento\", \"casa\"],\n        \"value_counts\": {\"departamento\": 9017, \"casa\": 6335}\n      }\n    },\n    \"net_usable_area\": {\n      \"numerical\": {\n        \"min\": 10.0, \"max\": 180116.0,\n        \"mean\": 250.34, \"std\": 2851.11\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"user-manual/#validation-features","title":"Validation Features","text":"<ul> <li>Data Type Validation: Ensures correct column types</li> <li>Range Validation: Validates numerical ranges  </li> <li>Categorical Validation: Checks valid category values</li> <li>Statistical Profiling: Tracks data distribution changes</li> </ul>"},{"location":"user-manual/#configuration","title":"\u2699\ufe0f Configuration","text":""},{"location":"user-manual/#environment-variables","title":"Environment Variables","text":"Variable Description Default <code>DATA_VERSION</code> Data version to use <code>v3</code> <code>MODEL_METRIC</code> Model selection metric <code>rmse</code> <code>API_HOST</code> Server host <code>0.0.0.0</code> <code>API_PORT</code> Server port <code>8000</code> <code>API_WORKERS</code> Worker processes <code>1</code> <code>LOG_LEVEL</code> Logging level <code>INFO</code>"},{"location":"user-manual/#model-loading","title":"Model Loading","text":"<pre><code># Load from pipeline outputs (default)\nMODEL_LOAD_TARGET=pipeline\n\n# Load from jupyter outputs  \nMODEL_LOAD_TARGET=jupyter\n\n# Specify exact model version\nMODEL_VERSION=v3.4\n</code></pre>"},{"location":"user-manual/#monitoring","title":"\ud83d\udcca Monitoring","text":""},{"location":"user-manual/#logging-structure","title":"Logging Structure","text":"<pre><code>outputs/\n\u251c\u2500\u2500 pipeline/logs/PropertyValuationPipeline.log    # Training logs\n\u251c\u2500\u2500 predictions/api.log                            # API access logs\n\u2514\u2500\u2500 predictions/error.log                          # Error logs\n</code></pre>"},{"location":"user-manual/#log-formats","title":"Log Formats","text":"<p>API Logs: <pre><code>{\n  \"timestamp\": \"2025-08-02T22:05:21.892530\",\n  \"endpoint\": \"/api/v3/predictions\",\n  \"status_code\": 200,\n  \"response_time\": 0.0234,\n  \"model_version\": \"v3.4_gradient_boosting\",\n  \"prediction\": 185000000\n}\n</code></pre></p> <p>Pipeline Logs: <pre><code>{\n  \"timestamp\": \"2025-08-02T22:05:21.892530\",\n  \"component\": \"ModelTraining\",\n  \"model_type\": \"gradient_boosting\",\n  \"data_version\": \"v3.4\",\n  \"metrics\": {\"rmse\": 5710.23, \"mae\": 2624.52}\n}\n</code></pre></p>"},{"location":"user-manual/#testing","title":"\ud83e\uddea Testing","text":""},{"location":"user-manual/#api-testing","title":"API Testing","text":"<pre><code># Unit tests\npython -m pytest tests/test_api.py\n\n# Integration tests\npython -m pytest tests/test_integration.py\n</code></pre>"},{"location":"user-manual/#troubleshooting","title":"\ud83d\udea8 Troubleshooting","text":""},{"location":"user-manual/#common-issues","title":"Common Issues","text":"<p>Model Loading Errors</p> <p>Problem: Model file not found</p> <p>Solution:  <pre><code># Check available models\nls outputs/pipeline/models/\n\n# Retrain if necessary\npython scripts/pipeline.py\n</code></pre></p> <p>Version Mismatch</p> <p>Problem: API version doesn't match model version</p> <p>Solution:  <pre><code># Ensure consistent versioning\nexport DATA_VERSION=v3\nexport MODEL_VERSION=v3.4\npython scripts/run_api.py\n</code></pre></p> <p>Performance Issues</p> <p>Problem: Slow API responses</p> <p>Solution:  <pre><code># Enable model caching\nexport MODEL_CACHE_SIZE=5\n\n# Increase workers\nexport API_WORKERS=4\n</code></pre></p>"},{"location":"user-manual/#performance-metrics","title":"\ud83d\udcc8 Performance Metrics","text":""},{"location":"user-manual/#model-performance-v34","title":"Model Performance (v3.4)","text":"Metric Value Target RMSE 5,710 CLP &lt; 6,000 CLP MAE 2,625 CLP &lt; 3,000 CLP MAPE 46.7% &lt; 50% Training Samples 15,352 15,000+"},{"location":"user-manual/#api-performance","title":"API Performance","text":"Metric Current Target Response Time 23ms &lt; 50ms Throughput 1,000 req/min 1,500 req/min Availability 99.9% 99.95% Error Rate 0.1% &lt; 0.5%"},{"location":"user-manual/#data-source-abstraction","title":"\ud83d\uddc4\ufe0f Data Source Abstraction","text":"<p>The system includes a flexible data source abstraction layer designed for future database integration while maintaining compatibility with the current file-based implementation.</p>"},{"location":"user-manual/#architecture_1","title":"Architecture","text":"<p>The data source abstraction provides a clean interface that can be easily switched between file-based and database-based implementations:</p> <pre><code># Current (file-based)\nfile_source = FileDataSource(\"/path/to/data\")\nrepo = DataRepository(file_source)\n\n# Future (database)\ndb_source = DatabaseDataSource(\"postgresql://user:pass@host/db\")\nrepo = DataRepository(db_source)\n\n# Same interface for both\ntrain_data = repo.get_train_data()\n</code></pre>"},{"location":"user-manual/#components","title":"Components","text":""},{"location":"user-manual/#datasource-abstract-base-class","title":"DataSource (Abstract Base Class)","text":"<p>Defines the interface for all data sources: - <code>load_data()</code> - Load data by type and version - <code>save_data()</code> - Save processed data - <code>list_versions()</code> - List available data versions - <code>get_latest_version()</code> - Get the most recent version</p>"},{"location":"user-manual/#filedatasource","title":"FileDataSource","text":"<p>Current implementation for file-based data storage: - Handles CSV file operations - Manages version-based file naming - Compatible with existing pipeline logic</p>"},{"location":"user-manual/#databasedatasource","title":"DatabaseDataSource","text":"<p>Future implementation for database integration: - Supports SQL/NoSQL databases - Handles connection management - Provides version-based table queries</p>"},{"location":"user-manual/#datarepository","title":"DataRepository","text":"<p>Repository pattern for clean data access: - <code>get_train_data()</code> - Retrieve training data - <code>get_test_data()</code> - Retrieve test data - <code>save_processed_data()</code> - Store processed results - <code>get_latest_data()</code> - Get most recent data version</p>"},{"location":"user-manual/#migration-path","title":"Migration Path","text":"<p>The abstraction allows seamless migration from files to database:</p> <ol> <li>Current State: File-based operations</li> <li>Future State: Database operations with same interface</li> <li>Zero Pipeline Changes: Same method calls work for both</li> </ol>"},{"location":"user-manual/#integration-examples","title":"\ud83d\udd17 Integration Examples","text":""},{"location":"user-manual/#batch-processing","title":"Batch Processing","text":"<pre><code>import requests\n\ndef batch_valuate_properties(properties):\n    response = requests.post(\n        \"http://localhost:8000/api/v3/predictions/batch\",\n        headers={\"X-API-Key\": \"your_key\"},\n        json={\"properties\": properties}\n    )\n    return response.json()\n</code></pre>"},{"location":"user-manual/#real-time-integration","title":"Real-time Integration","text":"<pre><code>import asyncio\nimport aiohttp\n\nasync def real_time_valuation(property_data):\n    async with aiohttp.ClientSession() as session:\n        async with session.post(\n            \"http://localhost:8000/api/v3/predictions\",\n            headers={\"X-API-Key\": \"your_key\"},\n            json={\"features\": property_data}\n        ) as response:\n            return await response.json()\n</code></pre>"}]}